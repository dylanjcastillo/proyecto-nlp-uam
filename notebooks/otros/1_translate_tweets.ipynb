{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea37434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import spacy_fastlang\n",
    "\n",
    "from rapidfuzz.fuzz import ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bd10b",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5482dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/tweets_with_spacy_lang.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a591a0",
   "metadata": {},
   "source": [
    "## Generate column with real language (if not exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06eff078",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"spacy_lang\" in df.columns:\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "    nlp.add_pipe(\"language_detector\")\n",
    "\n",
    "    df[\"spacy_lang\"] = df.text.map(lambda x: nlp(x)._.language)\n",
    "    df.to_csv(\"../../data/tweets_with_spacy_lang.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd495c",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d692881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"is_rt\"] = df[\"text\"].str[:2] == \"RT\"\n",
    "df[\"label\"] = np.nan\n",
    "df[\"id_tweet\"] = \"X1Y2Z3-\" + df.id_tweet.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825e128",
   "metadata": {},
   "source": [
    "## Split into files to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd80f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_translate = (\n",
    "    df\n",
    "    .loc[\n",
    "        (df.lang != \"es\") | (df.spacy_lang != \"es\"),\n",
    "        [\"id_tweet\", \"text\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed681cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134353 tweets to translate. Will split into 9 parts of 15000 tweets each.\n"
     ]
    }
   ],
   "source": [
    "step = 15_000\n",
    "size = df_to_translate.shape[0]\n",
    "parts = math.ceil(size / step) \n",
    "dfs = [None] * parts \n",
    "\n",
    "print(f\"{size} tweets to translate. Will split into {parts} parts of {step} tweets each.\")\n",
    "for i, min_ in enumerate(range(0, size, step)): \n",
    "    max_ = min_ + step\n",
    "    if max_ > size:\n",
    "        max_ = size              \n",
    "    #print(min_, max_)\n",
    "    dfs[i] = df_to_translate.iloc[min_:max_,]\n",
    "    #print(dfs[i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcc3a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "rows = []\n",
    "for i, df_ in enumerate(dfs):\n",
    "    rows.append(df_.shape[0])\n",
    "    ids.extend(df_.id_tweet.tolist())\n",
    "    df_.to_excel(f\"../../data/translations/input/tweets_to_translate_{i}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "925b3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(rows) == size\n",
    "assert df.id_tweet[df.lang != \"es\"].isin(ids).all()\n",
    "assert np.isin(ids, df.id_tweet.tolist()).all() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b08c6f1",
   "metadata": {},
   "source": [
    "Go to Google Translate and upload the files to translate, then continue with next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ad647",
   "metadata": {},
   "source": [
    "## Add translations to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dce3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_translations = []\n",
    "for i in range(parts):\n",
    "    all_translations.append(pd.read_excel(f\"../../data/translations/output/tweets_to_translate_{i}.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19f618ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_translations = pd.concat(all_translations)\n",
    "df_all_translations.rename(columns={\" texto\": \"texto_traducido\"}, inplace=True)\n",
    "df_all_translations[\"id_tweet\"] = df_all_translations.id_tweet.str.strip()\n",
    "df_all_translations[\"texto_traducido\"] = df_all_translations.texto_traducido.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c78402bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26    129659\n",
       "25      4671\n",
       "27        19\n",
       "24         3\n",
       "28         1\n",
       "Name: id_tweet, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_translations.id_tweet.str.len().value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c72a4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_id(id_tweet):\n",
    "    most_similar = None \n",
    "    most_similar_ratio = -1\n",
    "    for id_comp in ids:\n",
    "        ratio_ = ratio(id_tweet, id_comp, score_cutoff=90)\n",
    "        if ratio_ > most_similar_ratio:\n",
    "            most_similar = id_comp\n",
    "            most_similar_ratio = ratio_\n",
    "    return most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa608b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_tweet_ids = df_all_translations[~df_all_translations.id_tweet.isin(ids)].id_tweet.map(get_most_similar_id)\n",
    "df_all_translations.loc[~df_all_translations.id_tweet.isin(ids), \"id_tweet\"] = fixed_tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6276fbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_tweet_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "424a5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_all_translations.shape[0] == size\n",
    "assert df_all_translations.id_tweet.isin(ids).all()\n",
    "assert df[df.lang != \"es\"].id_tweet.isin(df_all_translations.id_tweet).all()\n",
    "assert (df_all_translations.id_tweet.str[:6] == \"X1Y2Z3\").all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e53be",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "171ef5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df.merge(df_all_translations, how=\"left\", on=\"id_tweet\")\n",
    "df_full[\"id_tweet\"] = df_full.id_tweet.str[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62b4f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>app</th>\n",
       "      <th>id_user</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>stauses</th>\n",
       "      <th>location</th>\n",
       "      <th>...</th>\n",
       "      <th>user_retweeted</th>\n",
       "      <th>quoted_id</th>\n",
       "      <th>user_quoted</th>\n",
       "      <th>first_HT</th>\n",
       "      <th>lang</th>\n",
       "      <th>link</th>\n",
       "      <th>spacy_lang</th>\n",
       "      <th>is_rt</th>\n",
       "      <th>label</th>\n",
       "      <th>texto_traducido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_tweet, date, author, text, app, id_user, followers, following, stauses, location, urls, geolocation, RT_count, favorite_count, url_media, type_media, quoted, relation, replied_id, user_replied, retweeted_id, user_retweeted, quoted_id, user_quoted, first_HT, lang, link, spacy_lang, is_rt, label, texto_traducido]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.loc[(df_full.texto_traducido.isna()) & (df_full.lang != 'es') & (df_full.text.str.len() >= 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a6fe32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv(\"../../data/tweets_traducidos.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "45997051a618164a2aaa1103953d009f53296a5c7fd869ab5dc2d414330730df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
