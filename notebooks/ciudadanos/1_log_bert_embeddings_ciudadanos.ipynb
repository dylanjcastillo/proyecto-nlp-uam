{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_q-Nu53y4IT"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet sentence-transformers emoji"
      ],
      "id": "R_q-Nu53y4IT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SrQ-eZ5-zoyi",
        "outputId": "b4f0c7bd-8cb7-48a4-b008-3988cf9e8899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    DATA_PATH = \"/content/drive/MyDrive/nlp-tweets-classification/ciudadanos/\"\n",
        "    ARTIFACTS_PATH = \"/content/drive/MyDrive/nlp-tweets-classification/ciudadanos/\"\n",
        "except ModuleNotFoundError:\n",
        "    DATA_PATH = \"../../data/\"\n",
        "    ARTIFACTS_PATH = \"../../artifacts/\"\n",
        "    running_in_colab = False\n"
      ],
      "id": "SrQ-eZ5-zoyi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25e42212"
      },
      "source": [
        "## Imports\n"
      ],
      "id": "25e42212"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bQ_E89Xbzlk7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import random\n",
        "import uuid\n",
        "\n",
        "from emoji import demojize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    silhouette_samples,\n",
        "    silhouette_score,\n",
        "    cohen_kappa_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    average_precision_score,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedKFold,\n",
        "    GridSearchCV,\n",
        "    StratifiedShuffleSplit,\n",
        ")\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "np.random.seed(SEED)\n"
      ],
      "id": "bQ_E89Xbzlk7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ac68cd"
      },
      "source": [
        "## Utility functions\n"
      ],
      "id": "54ac68cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9928c2c4"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if \"http\" not in t]\n",
        "    tokens = [demojize(t, language=\"es\") for t in tokens]\n",
        "    tokens = [t.replace(\"@\", \"\") for t in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "def get_hyperparams_space(model_name):\n",
        "    if model_name == \"log\":\n",
        "        hyperparams = dict(\n",
        "            C=[0.001, 0.01, 0.1, 1, 10, 100],\n",
        "            penalty=[\"l1\", \"l2\"],\n",
        "            class_weight=[\"balanced\", None],\n",
        "        )\n",
        "    elif model_name == \"rf\":\n",
        "        hyperparams = dict(\n",
        "            n_estimators=[120, 500, 1200],\n",
        "            max_depth=[5, 8, 15, 25],\n",
        "            class_weight=[\"balanced\", None],\n",
        "        )\n",
        "    elif model_name == \"svc\":\n",
        "        hyperparams = dict(\n",
        "            C=[0.001, 0.01, 0.1, 1, 10, 100], class_weight=[\"balanced\", None]\n",
        "        )\n",
        "    elif model_name == \"xgb\":\n",
        "        hyperparams = dict(\n",
        "            eta=[0.01, 0.05, 0.1],\n",
        "            gamma=[0.1, 0.5, 1],\n",
        "            max_depth=[3, 12, 25],\n",
        "            min_child_weight=[1, 3, 7],\n",
        "            subsample=[0.6, 0.8, 1],\n",
        "            colsample_bytree=[0.6, 0.8, 1],\n",
        "        )\n",
        "    elif model_name == \"nb\":\n",
        "        hyperparams = dict()\n",
        "    elif model_name == \"lgbm\":\n",
        "        hyperparams = dict(\n",
        "            learning_rate=[0.01, 0.05, 0.1],\n",
        "        )\n",
        "    else:\n",
        "        raise Exception(f\"No hyperparams for model {model_name}\")\n",
        "    return hyperparams\n",
        "\n",
        "\n",
        "def get_model(model_name):\n",
        "    if model_name == \"lgbm\":\n",
        "        return LGBMClassifier()\n",
        "    elif model_name == \"hist\":\n",
        "        return HistGradientBoostingClassifier()\n",
        "    elif model_name == \"log\":\n",
        "        return LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\")\n",
        "    elif model_name == \"rf\":\n",
        "        return RandomForestClassifier(\n",
        "            n_jobs=-1,\n",
        "            n_estimators=1200,\n",
        "        )\n",
        "    elif model_name == \"nb\":\n",
        "        return GaussianNB()\n",
        "    elif model_name == \"xgb\":\n",
        "        return XGBClassifier(\n",
        "            tree_method=\"hist\", use_label_encoder=False, max_depth=10, eta=0.1\n",
        "        )\n",
        "    elif model_name == \"svc\":\n",
        "        return LinearSVC(class_weight=\"balanced\")\n",
        "    else:\n",
        "        raise ValueError(format)"
      ],
      "id": "9928c2c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "509b840e"
      },
      "source": [
        "## Set notebook parameters\n"
      ],
      "id": "509b840e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a580a384"
      },
      "outputs": [],
      "source": [
        "col_target = \"label\"\n",
        "dataset_name = \"all_citizens_labeled_20220911.json\"\n",
        "model_name = \"log\"\n",
        "n_splits = 10\n",
        "use_precalculated_embeddings = True\n",
        "run_hyperparams_search = True \n",
        "use_full_dataset = True "
      ],
      "id": "a580a384"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42905b26"
      },
      "source": [
        "## Read data\n"
      ],
      "id": "42905b26"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1204c89a",
        "outputId": "27ab8c5c-fe21-4b86-cdd0-69964c82f5d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_json(DATA_PATH + dataset_name).reset_index(drop=True)\n",
        "df_ayuntamientos = pd.read_csv(DATA_PATH + 'tweets_traducidos.csv', low_memory= False)\n",
        "ayuntamientos = df_ayuntamientos.author.unique()\n",
        "\n",
        "df_full = pd.read_csv(DATA_PATH + \"all_citizens_joined.csv\").drop_duplicates(subset=[\"id_tweet\"])\n",
        "df_full[\"is_ayuntamiento\"] = df_full.author.isin(ayuntamientos)\n",
        "\n",
        "df_test = df_full.loc[\n",
        "    (df_full.relation != \"RT\") & (df_full.lang == \"es\") & (df_full.is_ayuntamiento == False)\n",
        "].reset_index(drop=True)\n",
        "\n",
        "if not use_full_dataset:\n",
        "    df_test = df_test.sample(1000).reset_index(drop=True)"
      ],
      "id": "1204c89a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOTvL51j0brB"
      },
      "source": [
        "## Create embeddings\n"
      ],
      "id": "kOTvL51j0brB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_X-xlv70ffu"
      },
      "outputs": [],
      "source": [
        "if use_precalculated_embeddings:\n",
        "    df_embeddings = pd.read_json(DATA_PATH + \"tweets_embeddings_ciudadanos.json\")\n",
        "else:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    cleaned_tweets = [clean_text(tweet) for tweet in df_full.text]\n",
        "\n",
        "    model = SentenceTransformer(\"hiiamsid/sentence_similarity_spanish_es\")\n",
        "    embeddings = model.encode(cleaned_tweets)\n",
        "\n",
        "    df_embeddings = pd.concat([df_full[\"link\"], pd.DataFrame(embeddings)], axis=1)\n",
        "    df_embeddings.to_json(DATA_PATH + \"tweets_embeddings_ciudadanos.json\")\n",
        "\n",
        "assert df.link.isin(df_embeddings.link).all()"
      ],
      "id": "T_X-xlv70ffu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62a4e6c4"
      },
      "source": [
        "## Train model\n"
      ],
      "id": "62a4e6c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7448396"
      },
      "outputs": [],
      "source": [
        "df_results = pd.DataFrame()\n",
        "\n",
        "x_test = df_test[[\"link\"]].merge(df_embeddings, how=\"inner\", on=\"link\").drop(columns=\"link\")\n",
        "df_label = (\n",
        "    df[[\"link\", col_target]].merge(df_embeddings, how=\"inner\", on=\"link\").drop(columns=\"link\")\n",
        ")\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(df_label[col_target])\n",
        "joblib.dump(le, ARTIFACTS_PATH + f\"label_encoder_ciudadanos.joblib\")\n",
        "\n",
        "df_label = df_label.sample(frac=1).reset_index(drop=True).dropna()\n",
        "df_label[\"kfold\"] = -1\n",
        "\n",
        "if n_splits > 1:\n",
        "    kf = StratifiedKFold(n_splits=n_splits)\n",
        "    for f, (t, v) in enumerate(kf.split(X=df_label, y=df_label[col_target])):\n",
        "        df_label.loc[v, \"kfold\"] = f\n",
        "else:\n",
        "    ss = StratifiedShuffleSplit(n_splits=1, test_size=0.15)\n",
        "    f = next(ss.split(X=df_label, y=df_label[col_target]))\n",
        "    t = f[0]\n",
        "    v = f[1]\n",
        "    df_label.loc[v, \"kfold\"] = 0\n",
        "\n",
        "f1_scores = []\n",
        "kappa_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "test_probas = []\n",
        "l1_f1_scores = []\n",
        "l2_f1_scores = []\n",
        "l3_f1_scores = []\n",
        "l4_f1_scores = []\n",
        "l5_f1_scores = []\n",
        "l1_precision_scores = []\n",
        "l2_precision_scores = []\n",
        "l3_precision_scores = []\n",
        "l4_precision_scores = []\n",
        "l5_precision_scores = []\n",
        "l1_recall_scores = []\n",
        "l2_recall_scores = []\n",
        "l3_recall_scores = []\n",
        "l4_recall_scores = []\n",
        "l5_recall_scores = []\n",
        "\n",
        "print(f\"Training {model_name}\")\n",
        "for f in range(n_splits):\n",
        "    df_train = df_label[df_label.kfold != f].reset_index(drop=True)\n",
        "    df_val = df_label[df_label.kfold == f].reset_index(drop=True)\n",
        "\n",
        "    print(\n",
        "        f\"Split {f}: {df_train.shape[0]} observations for training / {df_val.shape[0]} observations for validation\"\n",
        "    )\n",
        "    x_train = df_train.iloc[:, 1:-1]\n",
        "    x_val = df_val.iloc[:, 1:-1]\n",
        "    y_train = le.transform(df_train[col_target])\n",
        "    y_val = le.transform(df_val[col_target])\n",
        "\n",
        "    if run_hyperparams_search:\n",
        "        space = get_hyperparams_space(model_name)\n",
        "        cv_inner = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "        search = GridSearchCV(\n",
        "            get_model(model_name), space, scoring=\"f1_macro\", cv=cv_inner, refit=True\n",
        "        )\n",
        "        result = search.fit(x_train, y_train)\n",
        "        model = result.best_estimator_\n",
        "    else:\n",
        "        model = get_model(model_name)\n",
        "\n",
        "    joblib.dump(model, ARTIFACTS_PATH + f\"model_{model_name}_{f}.joblib\")\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "    preds = model.predict(x_val)\n",
        "    test_probas.append(model.predict_proba(x_test))\n",
        "\n",
        "    f1_ind_scores = f1_score(y_val, preds, average=None)\n",
        "    precision_ind_scores = precision_score(y_val, preds, average=None)\n",
        "    recall_ind_scores = recall_score(y_val, preds, average=None)\n",
        "\n",
        "    l1_f1_scores.append(f1_ind_scores[0])\n",
        "    l2_f1_scores.append(f1_ind_scores[1])\n",
        "    l3_f1_scores.append(f1_ind_scores[2])\n",
        "    l4_f1_scores.append(f1_ind_scores[0])\n",
        "    l5_f1_scores.append(f1_ind_scores[1])\n",
        "\n",
        "    l1_precision_scores.append(precision_ind_scores[0])\n",
        "    l2_precision_scores.append(precision_ind_scores[1])\n",
        "    l3_precision_scores.append(precision_ind_scores[2])\n",
        "    l4_precision_scores.append(precision_ind_scores[3])\n",
        "    l5_precision_scores.append(precision_ind_scores[4])\n",
        "\n",
        "    l1_recall_scores.append(recall_ind_scores[0])\n",
        "    l2_recall_scores.append(recall_ind_scores[1])\n",
        "    l3_recall_scores.append(recall_ind_scores[2])\n",
        "    l4_recall_scores.append(recall_ind_scores[3])\n",
        "    l5_recall_scores.append(recall_ind_scores[4])\n",
        "\n",
        "    f1_scores.append(f1_score(y_val, preds, average=\"macro\"))\n",
        "    kappa_scores.append(cohen_kappa_score(y_val, preds))\n",
        "    precision_scores.append(precision_score(y_val, preds, average=\"macro\"))\n",
        "    recall_scores.append(recall_score(y_val, preds, average=\"macro\"))\n",
        "    acc_scores.append(accuracy_score(y_val, preds))\n",
        "\n",
        "    # print(classification_report(y_val, preds, target_names=le.classes_))\n",
        "    print(f\"f1: {np.mean(f1_scores):.2f}, kappa: {np.mean(kappa_scores):.2f}\")\n",
        "\n",
        "df_results = pd.concat(\n",
        "    [\n",
        "        df_results,\n",
        "        pd.DataFrame(\n",
        "            dict(\n",
        "                target=col_target,\n",
        "                model=[model_name],\n",
        "                n_splits=n_splits,\n",
        "                f1=np.mean(f1_scores),\n",
        "                accuracy=np.mean(acc_scores),\n",
        "                kappa=np.mean(kappa_scores),\n",
        "                precision=np.mean(precision_scores),\n",
        "                recall=np.mean(recall_scores),\n",
        "                l1_f1=np.mean(l1_f1_scores),\n",
        "                l2_f1=np.mean(l2_f1_scores),\n",
        "                l3_f1=np.mean(l3_f1_scores),\n",
        "                l4_f1=np.mean(l4_f1_scores),\n",
        "                l5_f1=np.mean(l5_f1_scores),\n",
        "                l1_precision=np.mean(l1_precision_scores),\n",
        "                l2_precision=np.mean(l2_precision_scores),\n",
        "                l3_precision=np.mean(l3_precision_scores),\n",
        "                l4_precision=np.mean(l4_precision_scores),\n",
        "                l5_precision=np.mean(l5_precision_scores),\n",
        "                l1_recall=np.mean(l1_recall_scores),\n",
        "                l2_recall=np.mean(l2_recall_scores),\n",
        "                l3_recall=np.mean(l3_recall_scores),\n",
        "                l4_recall=np.mean(l4_recall_scores),\n",
        "                l5_recall=np.mean(l5_recall_scores),\n",
        "                f1_scores=str([round(s, 2) for s in f1_scores]),\n",
        "                kappa_scores=str([round(s, 2) for s in kappa_scores]),\n",
        "                precision_scores=str([round(s, 2) for s in precision_scores]),\n",
        "                recall_scores=str([round(s, 2) for s in recall_scores]),\n",
        "            )\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "df_results = df_results.rename(\n",
        "    columns={\n",
        "        \"l1_f1\": f\"{le.classes_[0]}_f1\",\n",
        "        \"l2_f1\": f\"{le.classes_[1]}_f1\",\n",
        "        \"l3_f1\": f\"{le.classes_[2]}_f1\",\n",
        "        \"l4_f1\": f\"{le.classes_[3]}_f1\",\n",
        "        \"l5_f1\": f\"{le.classes_[4]}_f1\",\n",
        "        \"l1_precision\": f\"{le.classes_[0]}_precision\",\n",
        "        \"l2_precision\": f\"{le.classes_[1]}_precision\",\n",
        "        \"l3_precision\": f\"{le.classes_[2]}_precision\",\n",
        "        \"l4_precision\": f\"{le.classes_[3]}_precision\",\n",
        "        \"l5_precision\": f\"{le.classes_[4]}_precision\",\n",
        "        \"l1_recall\": f\"{le.classes_[0]}_recall\",\n",
        "        \"l2_recall\": f\"{le.classes_[1]}_recall\",\n",
        "        \"l3_recall\": f\"{le.classes_[2]}_recall\",\n",
        "        \"l4_recall\": f\"{le.classes_[3]}_recall\",\n",
        "        \"l5_recall\": f\"{le.classes_[4]}_recall\",\n",
        "    }\n",
        ")"
      ],
      "id": "f7448396"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90b9a2db"
      },
      "source": [
        "## Save performance metrics \n"
      ],
      "id": "90b9a2db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "966fc616"
      },
      "outputs": [],
      "source": [
        "results_path = DATA_PATH + \"results.csv\"\n",
        "if run_hyperparams_search:\n",
        "    results_path = DATA_PATH + \"results_best_hyperparams.csv\"\n",
        "df_results.to_csv(results_path, index=False)"
      ],
      "id": "966fc616"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6fQ2TY6facL"
      },
      "outputs": [],
      "source": [
        "df_results.T"
      ],
      "id": "t6fQ2TY6facL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sviug2NojL07"
      },
      "outputs": [],
      "source": [
        "df_train[col_target].value_counts(normalize=True)"
      ],
      "id": "sviug2NojL07"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQ-oJOLaWUX"
      },
      "source": [
        "## Add probabilities and predictions to dataset "
      ],
      "id": "ZHQ-oJOLaWUX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SssN5ylZQP47"
      },
      "outputs": [],
      "source": [
        "col_probas = []\n",
        "for j in range(x_test.shape[0]):\n",
        "  temp_probas = np.array([test_probas[i][j] for i in range(len(test_probas))])\n",
        "  col_probas.append(temp_probas.sum(axis=0) / temp_probas.sum())\n",
        "\n",
        "df_test[col_target] = le.inverse_transform(np.argmax(np.array(col_probas), axis=1))\n",
        "\n",
        "df_probas = pd.DataFrame(col_probas).rename(\n",
        "    columns={\n",
        "        0: \"prob_\" + le.inverse_transform([0])[0],\n",
        "        1: \"prob_\" + le.inverse_transform([1])[0],\n",
        "        2: \"prob_\" + le.inverse_transform([2])[0],\n",
        "        3: \"prob_\" + le.inverse_transform([3])[0],\n",
        "        4: \"prob_\" + le.inverse_transform([4])[0],\n",
        "    }\n",
        ")\n",
        "\n",
        "# concat df_test with df_counts\n",
        "rows_prev = df_test.shape[0]\n",
        "df_test = pd.concat([df_test, df_probas], axis=1)\n",
        "\n",
        "assert df_test.shape[0] == rows_prev"
      ],
      "id": "SssN5ylZQP47"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsiHvQ-awsJV"
      },
      "source": [
        "## Add sentiment analysis and relational user columns"
      ],
      "id": "rsiHvQ-awsJV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTKWiRtBwleD"
      },
      "outputs": [],
      "source": [
        "df_additional_cols = pd.read_csv(DATA_PATH + \"citizens_final_with_sentiment_analysis_and_relational_user_col_final.csv\")\n",
        "df_additional_cols = (\n",
        "    df_additional_cols.drop(\n",
        "    columns=[\n",
        "        'text', \n",
        "        'label', \n",
        "        'destructivo_proba', \n",
        "        'entretenido_proba',\n",
        "        'expresivo_proba', \n",
        "        'informativo_colaborador_proba',\n",
        "        'informativo_demandante_proba']\n",
        "  ).rename(\n",
        "      columns={ \n",
        "          \"NEG\": \"prob_neg\",\n",
        "          \"NEU\": \"prob_neu\",\n",
        "          \"POS\": \"prob_pos\",\n",
        "          \"others\": \"prob_others\",\n",
        "          \"joy\": \"prob_joy\",\n",
        "          \"sadness\": \"prob_sadness\",\n",
        "          \"anger\": \"prob_anger\",\n",
        "          \"surprise\": \"prob_surprise\",\n",
        "          \"disgust\": \"prob_disgust\",\n",
        "          \"fear\": \"prob_fear\",\n",
        "          \"hateful\": \"prob_hateful\",\n",
        "          \"targeted\": \"prob_targeted\",\n",
        "          \"aggressive\": \"prob_aggressive\"\n",
        "      }\n",
        "  ).drop_duplicates(subset=[\"id tweet\"])\n",
        ")\n",
        "df_additional_cols.columns = df_additional_cols.columns.str.lower().str.replace(\" \", \"_\")"
      ],
      "id": "jTKWiRtBwleD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwZFEm5Z6pKI"
      },
      "source": [
        "## Save final output"
      ],
      "id": "lwZFEm5Z6pKI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4lenydzJY8z"
      },
      "outputs": [],
      "source": [
        "df_test.columns"
      ],
      "id": "e4lenydzJY8z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFhtO7wxw4rI"
      },
      "outputs": [],
      "source": [
        "df_output = df_test.merge(\n",
        "    df_additional_cols, \n",
        "    how=\"left\", \n",
        "    on=\"id_tweet\", \n",
        "    validate=\"1:1\"\n",
        ") \n",
        "\n",
        "df_output.to_csv(DATA_PATH + f\"output_final_ciudadanos.csv\", index=False)\n",
        "df_output.sample(1000).to_csv(DATA_PATH + f\"sample_output_ciudadanos.csv\", index=False)"
      ],
      "id": "QFhtO7wxw4rI"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Tags",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 47.584666,
      "end_time": "2022-08-09T15:27:48.180714",
      "environment_variables": {},
      "exception": null,
      "input_path": "0_models_baseline_bert_embeddings.ipynb",
      "output_path": "papermill/0_models_baseline_bert_embeddings_decisiones_hist.ipynb",
      "parameters": {
        "col_target": "decisiones",
        "model_name": "hist"
      },
      "start_time": "2022-08-09T15:27:00.596048",
      "version": "2.3.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "45997051a618164a2aaa1103953d009f53296a5c7fd869ab5dc2d414330730df"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}